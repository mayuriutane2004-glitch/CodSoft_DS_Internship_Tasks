# Imports
import pickle
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score

# Calling the dataset
df = pd.read_csv('./advertising.csv')

# Display first few rows
print(df.head())

# Dimensions of dataset
print(f"Number of rows: {df.shape[0]}")
print(f"Number of columns: {df.shape[1]}")

# Checking for missing values
print(df.isna().sum())

# Correlation among variables
plt.figure(figsize=(10,6))
sns.heatmap(df.corr(), annot=True, fmt='.2f', cmap='coolwarm')
plt.title("Correlation Among Variables")
plt.show()

# Distribution of variables
df_melt = df.melt(value_vars=df.columns)
plt.figure(figsize=(12,6))
sns.boxplot(data=df_melt, x='variable', y='value')
plt.title('Distribution of Continuous Variables')
plt.xlabel('Variables')
plt.ylabel('Values')
plt.show()

# Getting X and y
X = df.drop('Sales', axis=1)
y = df['Sales']

# Splitting dataset into training and testing
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=101
)

print(f"""X Train: {X_train.shape}
X Test: {X_test.shape}
Y Train: {y_train.shape}
Y Test: {y_test.shape}""")

# Preprocessing
preprocess = Pipeline([
    ('scaler', StandardScaler())
])

# Model pipeline
model = Pipeline([
    ('preprocess', preprocess),
    ('regressor', RandomForestRegressor(n_estimators=100, random_state=101))
])

# Fit the model
model.fit(X_train, y_train)

# Prediction
y_pred = model.predict(X_test)

# Evaluate model
accuracy = round(100 * r2_score(y_test, y_pred), 2)
print(f'Testing Accuracy: {accuracy}%')

# Save the model
with open('./model.pkl', 'wb') as fp:
    pickle.dump(model, fp)

print("Model saved as 'model.pkl'")
